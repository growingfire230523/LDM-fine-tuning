{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. Clone repos and install requirements"
      ],
      "metadata": {
        "id": "25FCkMXnLTqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/CompVis/latent-diffusion.git\n",
        "!git clone https://github.com/CompVis/taming-transformers\n",
        "!pip install -e ./taming-transformers\n",
        "!pip install ipywidgets omegaconf>=2.0.0 pytorch-lightning>=1.0.8 torch-fidelity einops\n",
        "\n",
        "import sys\n",
        "sys.path.append(\".\")\n",
        "sys.path.append('./taming-transformers')\n",
        "from taming.models import vqgan # checking correct import from taming"
      ],
      "metadata": {
        "id": "frCfhXDtegZj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "139ed2f2-2b77-45ff-ee8d-6d19a9ecb97c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'latent-diffusion'...\n",
            "remote: Enumerating objects: 341, done.\u001b[K\n",
            "remote: Total 341 (delta 0), reused 0 (delta 0), pack-reused 341 (from 1)\u001b[K\n",
            "Receiving objects: 100% (341/341), 28.69 MiB | 23.83 MiB/s, done.\n",
            "Resolving deltas: 100% (143/143), done.\n",
            "Cloning into 'taming-transformers'...\n",
            "remote: Enumerating objects: 1342, done.\u001b[K\n",
            "remote: Counting objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 1342 (delta 0), reused 0 (delta 0), pack-reused 1341 (from 2)\u001b[K\n",
            "Receiving objects: 100% (1342/1342), 409.77 MiB | 36.26 MiB/s, done.\n",
            "Resolving deltas: 100% (282/282), done.\n",
            "Obtaining file:///content/taming-transformers\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from taming-transformers==0.0.1) (2.8.0+cu126)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from taming-transformers==0.0.1) (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from taming-transformers==0.0.1) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->taming-transformers==0.0.1) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->taming-transformers==0.0.1) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->taming-transformers==0.0.1) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->taming-transformers==0.0.1) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->taming-transformers==0.0.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->taming-transformers==0.0.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->taming-transformers==0.0.1) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->taming-transformers==0.0.1) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->taming-transformers==0.0.1) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->taming-transformers==0.0.1) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->taming-transformers==0.0.1) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->taming-transformers==0.0.1) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->taming-transformers==0.0.1) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->taming-transformers==0.0.1) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->taming-transformers==0.0.1) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->taming-transformers==0.0.1) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->taming-transformers==0.0.1) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->taming-transformers==0.0.1) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->taming-transformers==0.0.1) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->taming-transformers==0.0.1) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->taming-transformers==0.0.1) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->taming-transformers==0.0.1) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->taming-transformers==0.0.1) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->taming-transformers==0.0.1) (3.0.3)\n",
            "Installing collected packages: taming-transformers\n",
            "  Running setup.py develop for taming-transformers\n",
            "Successfully installed taming-transformers-0.0.1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch._six'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3473189466.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./taming-transformers'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtaming\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvqgan\u001b[0m \u001b[0;31m# checking correct import from taming\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/taming-transformers/taming/models/vqgan.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpytorch_lightning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmain\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minstantiate_from_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtaming\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiffusionmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEncoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/taming-transformers/main.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutilities\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrank_zero_only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtaming\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcustom_collate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/taming-transformers/taming/data/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtaming\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhelper_types\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAnnotation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_six\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstring_classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnp_str_obj_array_pattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch._six'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Define the Task (currently only superresolution is available, other tasks are coming soon)\n",
        "\n"
      ],
      "metadata": {
        "id": "OjWXUwWoYOaf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd latent-diffusion\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "mode = widgets.Select(options=['superresolution'],\n",
        "    value='superresolution', description='Task:')\n",
        "display(mode)"
      ],
      "metadata": {
        "id": "XfZjXxFAJHIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Download model checkpoint ( takes ~ 3 Min) and load model\n"
      ],
      "metadata": {
        "id": "stNDInCK5ooo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from notebook_helpers import get_model\n",
        "model = get_model(mode.value)"
      ],
      "metadata": {
        "id": "BPnyd-XUKbfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Optional step: Upload your own conditioning image for superresolution (height and width have to take values in [128, 192, 256])"
      ],
      "metadata": {
        "id": "kOKXx7UoGobG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from notebook_helpers import get_custom_cond\n",
        "get_custom_cond(mode.value)"
      ],
      "metadata": {
        "id": "hB_5u73E8rAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Select conditioning from available examples or the uploaded custom conditioning"
      ],
      "metadata": {
        "id": "RoIUhuYrDAVD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from notebook_helpers import get_cond_options, get_cond\n",
        "dir, options = get_cond_options(mode.value)\n",
        "cond_choice = widgets.RadioButtons(\n",
        "        options=options,\n",
        "        description='Select conditioning:',\n",
        "        disabled=False\n",
        "    )\n",
        "display(cond_choice)"
      ],
      "metadata": {
        "id": "Eo8f_3dLBpk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Run Model"
      ],
      "metadata": {
        "id": "3-2pDRRGsh4k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from notebook_helpers import run\n",
        "import os\n",
        "custom_steps = 100\n",
        "cond_choice_path = os.path.join(dir, cond_choice.value)\n",
        "logs = run(model[\"model\"], cond_choice_path, mode.value, custom_steps)"
      ],
      "metadata": {
        "id": "uXkBaR3-nlMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Display Sample"
      ],
      "metadata": {
        "id": "ADjlDRZHyx6P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import IPython.display as d\n",
        "from PIL import Image\n",
        "\n",
        "sample = logs[\"sample\"]\n",
        "sample = sample.detach().cpu()\n",
        "sample = torch.clamp(sample, -1., 1.)\n",
        "sample = (sample + 1.) / 2. * 255\n",
        "sample = sample.numpy().astype(np.uint8)\n",
        "sample = np.transpose(sample, (0, 2, 3, 1))\n",
        "print(sample.shape)\n",
        "a = Image.fromarray(sample[0])\n",
        "display(a)\n"
      ],
      "metadata": {
        "id": "aCoHC2jbq_Ka"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}